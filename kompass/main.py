#!/usr/bin/env python3
"""
Script simple pour scraper Kompass sans bloquer le navigateur
"""
import asyncio
import pandas as pd
from playwright.async_api import async_playwright
from datetime import datetime

import signal
import sys
import os
import glob
from config import SCRAPING_CONFIG, SELECTORS, OUTPUT_CONFIG

# Variable globale pour stocker les r√©sultats partiels
_partial_results = []


def _get_output_dir():
    """Return a directory next to the executable/app when frozen.

    - macOS (.app): dist/<Name>/ (parent of the .app bundle)
    - Windows: dist/<Name>/ (folder of the .exe)
    - Dev: folder of this source file
    """
    try:
        if getattr(sys, "frozen", False):
            exe_dir = os.path.dirname(sys.executable)
            # Detect macOS .app bundle and go three levels up to the dist folder
            if sys.platform == "darwin" and "/Contents/MacOS" in exe_dir.replace("\\", "/"):
                return os.path.abspath(os.path.join(exe_dir, "..", "..", ".."))
            return exe_dir
    except Exception:
        pass
    # Not frozen: write next to source
    return os.path.dirname(os.path.abspath(__file__))

def _save_partial_results():
    """Sauvegarde les r√©sultats partiels en cas d'interruption"""
    global _partial_results
    if _partial_results:
        try:
            df = pd.DataFrame(_partial_results)
            date_str = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
            out_dir = _get_output_dir()
            partial_file = os.path.join(out_dir, f"kompass_data_partial_{date_str}.xlsx")
            
            # Sauvegarder avec la m√™me structure que le fichier final
            with pd.ExcelWriter(partial_file, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name=OUTPUT_CONFIG['excel_sheets']['companies'], index=False)
            
            print(f"\n[SAUVEGARDE PARTIELLE] R√©sultats sauvegard√©s dans: {partial_file}")
            print(f"[SAUVEGARDE PARTIELLE] {len(_partial_results)} entreprises sauvegard√©es")
        except Exception as e:
            print(f"[ERREUR SAUVEGARDE PARTIELLE] {e}")

def _signal_handler(signum, frame):
    """Gestionnaire de signal pour les interruptions"""
    print(f"\n[INTERRUPTION D√âTECT√âE] Signal {signum} re√ßu")
    _save_partial_results()
    sys.exit(0)

async def fetch_siret_for_company(context, company_info, index, total):
    """R√©cup√®re le SIRET d'une entreprise dans un nouvel onglet"""
    if not company_info.get('detailUrl'):
        return company_info, ""
    
    page = None
    try:
        # Cr√©er un nouvel onglet dans le m√™me contexte de navigateur
        page = await context.new_page()
        
        # Aller sur la page principale puis naviguer vers le d√©tail
        full_url = f"https://fr.kompass.com/easybusiness{company_info['detailUrl']}"
        await page.goto(full_url, timeout=15000)
        
        # Attendre que le SIRET soit visible
        await page.wait_for_selector('#detail-registration-numbers', timeout=10000)
        
        # Extraire le SIRET
        siret = await page.evaluate("""
        () => {
            const siretElement = document.querySelector('#detail-registration-numbers');
            if (siretElement) {
                return siretElement.textContent.trim().replace(/\\s+/g, '');
            }
            return '';
        }
        """)
        
        print(f"  [{index+1}/{total}] ‚úÖ {company_info['company'][:40]:<40} SIRET: {siret}")
        return company_info, siret
        
    except Exception as e:
        print(f"  [{index+1}/{total}] ‚ùå {company_info['company'][:40]:<40} Erreur: {str(e)[:30]}")
        return company_info, ""
    finally:
        if page:
            try:
                await page.close()
            except:
                pass


async def wait_for_next_button_enabled(page, max_wait_time=3000, poll_interval=200):
    """
    Attend que le bouton next soit activ√© avec polling
    Args:
        page: Page Playwright
        max_wait_time: Temps maximum d'attente en millisecondes (d√©faut: 3000ms)
        poll_interval: Intervalle de polling en millisecondes (d√©faut: 200ms)
    Returns:
        tuple: (button_element, is_enabled) ou (None, False) si timeout
    """
    start_time = asyncio.get_event_loop().time()
    max_wait_seconds = max_wait_time / 1000
    poll_seconds = poll_interval / 1000
    
    print(f"‚è≥ Attente de l'activation du bouton next (max {max_wait_time}ms)...")
    
    while (asyncio.get_event_loop().time() - start_time) < max_wait_seconds:
        # Chercher le bouton next avec tous les s√©lecteurs
        next_button = None
        for selector in SELECTORS['next_button']:
            try:
                next_button = await page.query_selector(selector)
                if next_button:
                    break
            except:
                continue
        
        if next_button:
            try:
                # V√©rifier si le bouton est activ√©
                is_enabled = await next_button.is_enabled()
                is_disabled = await next_button.get_attribute('data-ng-disabled')
                
                # Le bouton est consid√©r√© comme activ√© si:
                # - is_enabled est True ET
                # - data-ng-disabled n'est pas "true" (ou est None)
                if is_enabled and is_disabled != "true":
                    elapsed = int((asyncio.get_event_loop().time() - start_time) * 1000)
                    print(f"‚úÖ Bouton next activ√© apr√®s {elapsed}ms")
                    return next_button, True
                else:
                    # Afficher le statut pour debug
                    print(f"üîÑ Bouton trouv√© mais d√©sactiv√© (enabled: {is_enabled}, disabled: {is_disabled})")
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur lors de la v√©rification du bouton: {e}")
        else:
            print("üîÑ Bouton next non trouv√©, nouvelle tentative...")
        
        # Attendre avant la prochaine v√©rification
        await asyncio.sleep(poll_seconds)
    
    # Timeout atteint
    elapsed = int((asyncio.get_event_loop().time() - start_time) * 1000)
    print(f"‚è∞ Timeout atteint apr√®s {elapsed}ms - bouton next non activ√©")
    return None, False

async def main():
    """Script principal de scraping"""
    print("=== Scraper Kompass EasyBusiness ===")
    print("Ce script va ouvrir un navigateur et vous guider pour le scraping")
    print("üí° Astuce: Appuyez sur Ctrl+C √† tout moment pour sauvegarder les r√©sultats partiels")
    print()
    
    # Configurer le gestionnaire de signal pour les interruptions
    signal.signal(signal.SIGINT, _signal_handler)
    signal.signal(signal.SIGTERM, _signal_handler)
    
    # R√©initialiser les r√©sultats partiels
    global _partial_results
    _partial_results.clear()
    
    # Demander le nombre de pages
    try:
        max_pages = int(input("Nombre de pages √† scraper (d√©faut: 3): ") or "3")
    except ValueError:
        max_pages = 3
    
    # Demander si on veut extraire les SIRET
    extract_siret = input("\nExtraire les num√©ros SIRET ? (y/n, d√©faut: n): ").lower().strip()
    extract_siret = extract_siret in ['y', 'yes', 'o', 'oui']
    
    # Si extraction SIRET activ√©e, demander le niveau de parall√©lisme
    parallel_limit = 5
    if extract_siret:
        try:
            parallel_limit = int(input("Nombre de pages de d√©tail SIRET en parall√®le (d√©faut: 5, max: 10): ") or "5")
            parallel_limit = min(parallel_limit, 10)  # Limiter √† 10 pour ne pas surcharger
        except ValueError:
            parallel_limit = 5
    
    print(f"\nConfiguration:")
    print(f"  Pages de r√©sultats: {max_pages}")
    if extract_siret:
        print(f"  Extraction SIRET: OUI ({parallel_limit} pages de d√©tail simultan√©es)")
    else:
        print(f"  Extraction SIRET: NON (scraping rapide)")
    
    # Confirmation
    confirm = input("\nVoulez-vous continuer ? (y/n): ").lower()
    if confirm != 'y':
        print("Annul√©")
        return
    
    all_companies = []
    
    async with async_playwright() as p:
        # Lancer le navigateur
        browser = await p.chromium.launch(
            headless=SCRAPING_CONFIG['headless'],
            args=['--no-sandbox', '--disable-blink-features=AutomationControlled']
        )
        context = await browser.new_context(
            user_agent=SCRAPING_CONFIG['user_agent']
        )
        page = await context.new_page()
        
        try:
            print("\n‚úÖ Navigateur lanc√©")
            print("üåê Navigation automatique vers Kompass EasyBusiness...")
            
            # Navigation automatique vers l'URL
            await page.goto("https://fr.kompass.com/easybusiness#/")
            print("‚úÖ Page Kompass EasyBusiness charg√©e")
            
            print("\nüìã Instructions:")
            print("1. Connectez-vous √† votre compte Kompass si n√©cessaire")
            print("2. Effectuez votre recherche et allez sur la page avec les r√©sultats")
            print("3. Revenez dans ce terminal et appuyez sur Entr√©e")
            print()
            print("‚è≥ En attente...")
            
            # Attendre que l'utilisateur soit pr√™t avec les r√©sultats
            input("Appuyez sur Entr√©e quand vous √™tes sur la page avec les r√©sultats de recherche...")
            
            # Attendre un peu pour que la page se charge
            await page.wait_for_timeout(2000)
            
            # V√©rifier que la page contient des r√©sultats
            try:
                await page.wait_for_selector('table tbody tr', timeout=10000)
                print("‚úÖ Page avec r√©sultats d√©tect√©e")
            except:
                print("‚ö†Ô∏è Aucun r√©sultat trouv√© sur cette page")
                return
            
            for page_num in range(1, max_pages + 1):
                print(f"\n{'='*60}")
                print(f"üìÑ Scraping de la page {page_num}/{max_pages}")
                print(f"{'='*60}")
                
                # Attendre que le tableau soit charg√©
                try:
                    await page.wait_for_selector(SELECTORS['main_table'], timeout=15000)
                except:
                    print("Tableau non trouv√©, tentative de recherche alternative...")
                
                # Extraire les informations de base + les liens de d√©tail
                company_links = await page.evaluate(f"""
                () => {{
                    const results = [];
                    const rows = document.querySelectorAll('table tbody tr');
                    
                    const selectors = {{
                        company: `{SELECTORS['company_name']}`,
                        phone: `{SELECTORS['phone_number']}`,
                        city: `{SELECTORS['city']}`,
                        address: `{SELECTORS['address']}`
                    }};
                    
                    rows.forEach((row, index) => {{
                        // Extraire les donn√©es de base
                        const companyElement = row.querySelector(selectors.company);
                        const phoneElement = row.querySelector(selectors.phone);
                        const cityElement = row.querySelector(selectors.city);
                        const addressElement = row.querySelector(selectors.address);
                        
                        // Trouver le lien de d√©tail (avec l'attribut data-ng-href)
                        const detailLink = row.querySelector('a[role="button"][data-ng-href^="#/detail/"]');
                        
                        const rowData = {{
                            company: companyElement?.textContent.trim() || '',
                            phone: phoneElement?.textContent.trim() || '',
                            city: cityElement?.textContent.trim() || '',
                            address: addressElement?.textContent.trim() || '',
                            detailUrl: detailLink?.getAttribute('data-ng-href') || detailLink?.getAttribute('href') || null
                        }};
                        
                        // Fallback pour le t√©l√©phone
                        if (!rowData.phone) {{
                            const phoneRegex = /(\\+33\\s?[0-9\\s\\.\\-]{{8,}})|(0[1-9][0-9\\s\\.\\-]{{8,}})/;
                            const match = row.textContent.match(phoneRegex);
                            if (match) rowData.phone = match[0].trim();
                        }}
                        
                        if (rowData.company || rowData.phone) {{
                            results.push(rowData);
                        }}
                    }});
                    
                    return results;
                }}
                """)
                
                print(f"‚úÖ Trouv√© {len(company_links)} entreprises sur cette page")
                
                # Si extraction SIRET activ√©e
                if extract_siret:
                    print(f"‚è≥ R√©cup√©ration des SIRET en parall√®le ({parallel_limit} simultan√©es)...\n")
                    
                    # R√©cup√©rer les SIRET en parall√®le avec limite de concurrence
                    semaphore = asyncio.Semaphore(parallel_limit)
                    
                    async def fetch_with_semaphore(company_info, idx):
                        async with semaphore:
                            return await fetch_siret_for_company(context, company_info, idx, len(company_links))
                    
                    tasks = [fetch_with_semaphore(info, idx) 
                            for idx, info in enumerate(company_links)]
                    results_with_siret = await asyncio.gather(*tasks)
                    
                    # Ajouter les donn√©es compl√®tes avec SIRET
                    for company_info, siret in results_with_siret:
                        company_data = {
                            'company': company_info['company'],
                            'phone': company_info['phone'],
                            'city': company_info['city'],
                            'address': company_info['address'],
                            'siret': siret
                        }
                        all_companies.append(company_data)
                        _partial_results.append(company_data)
                    
                    print(f"\nüìä Total collect√© jusqu'√† pr√©sent: {len(_partial_results)} entreprises")
                    print(f"   Dont {sum(1 for c in _partial_results if c.get('siret'))} avec SIRET")
                else:
                    # Mode rapide sans SIRET
                    for company_info in company_links:
                        company_data = {
                            'company': company_info['company'],
                            'phone': company_info['phone'],
                            'city': company_info['city'],
                            'address': company_info['address']
                        }
                        all_companies.append(company_data)
                        _partial_results.append(company_data)
                    
                    print(f"üìä Total collect√© jusqu'√† pr√©sent: {len(_partial_results)} entreprises")
                
                # Aller √† la page suivante si ce n'est pas la derni√®re page
                if page_num < max_pages:
                    try:
                        print(f"\n‚è≠Ô∏è  Navigation vers la page {page_num + 1}...")
                        
                        # Utiliser la fonction d'attente avec polling pour le bouton next
                        next_button, is_enabled = await wait_for_next_button_enabled(page)
                        
                        if next_button and is_enabled:
                            await next_button.click()
                            await page.wait_for_timeout(SCRAPING_CONFIG['page_delay'])
                            print(f"‚úÖ Navigation r√©ussie vers la page {page_num + 1}\n")
                        else:
                            print("‚ùå Bouton suivant non trouv√© ou non activ√©, arr√™t du scraping")
                            break
                            
                    except Exception as e:
                        print(f"‚ùå Erreur lors de la navigation vers la page suivante: {e}")
                        break
            
        except KeyboardInterrupt:
            print("\n[INTERRUPTION] Sauvegarde des r√©sultats partiels...")
            _save_partial_results()
            return
        except Exception as e:
            print(f"Erreur lors du scraping: {e}")
            _save_partial_results()
        
        finally:
            try:
                await context.close()
            except Exception:
                pass
            try:
                await browser.close()
            except Exception:
                pass
    
    # Afficher les r√©sultats
    print(f"\n{'='*60}")
    print(f"=== R√©sultats Finaux ===")
    print(f"{'='*60}")
    print(f"Entreprises trouv√©es: {len(all_companies)}")
    if extract_siret:
        print(f"Avec SIRET: {sum(1 for c in all_companies if c.get('siret'))}")
        print(f"Sans SIRET: {sum(1 for c in all_companies if not c.get('siret'))}")
    
    # Sauvegarder les r√©sultats finaux
    if all_companies:
        print("\nSauvegarde des r√©sultats finaux...")
        
        # Cr√©er le DataFrame des entreprises
        max_rows_env = os.getenv("KOMPASS_MAX_ROWS")
        if max_rows_env:
            try:
                limit = int(max_rows_env)
                if limit >= 0:
                    all_companies = all_companies[:limit]
                    print(f"Limitation active: enregistrement des {len(all_companies)} premi√®res entr√©es")
            except Exception:
                pass
        df_companies = pd.DataFrame(all_companies)
        
        # Sauvegarder en Excel (seulement les entreprises)
        out_dir = _get_output_dir()
        filename = os.path.join(
            out_dir,
            f"{OUTPUT_CONFIG['filename_prefix']}_{datetime.now().strftime(OUTPUT_CONFIG['date_format'])}.xlsx",
        )
        
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            if not df_companies.empty:
                df_companies.to_excel(writer, sheet_name=OUTPUT_CONFIG['excel_sheets']['companies'], index=False)
        
        print(f"‚úÖ R√©sultats finaux sauvegard√©s dans: {filename}")
    else:
        print("‚ùå Aucun r√©sultat √† sauvegarder")

if __name__ == "__main__":
    asyncio.run(main())
